---
title: "php2650_proj"
author: "Yifan Zhao"
date: "12/05/2022"
output:  md_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/yvonne/Downloads/PHP2650SL/php2650_project")

# setwd("/Users/yvonne/Downloads/PHP2650SL/php2650_project")
library(tidyverse)
library(gridExtra)
library(knitr)
library(kableExtra)
library(survival)
library(data.table)
library(ranger)
library(caret)
#  pdf_document
```


**Reference:**
https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-017-0383-8




# Survival Analysis

## Survival Data

* Goal: 
    * Assess the effect of risk factors on survival time - time until an event occurs, for example, death, diagnosis recovery, etc.
    * Estimate and interpret survival
    * Compare survival time / curve between groups

* Outcome: 
  * The outcome of interest is a combination of continuous variable represents time to event and a binary variable represents censoring status: Y = [T, C]  
  * T: Observed survival time
  * C: Censoring (or event) status
  

* Data snapshot:

```{r ,echo=FALSE}
include_graphics("figures/f1_data.png")
```



## Censoring

Consider $Y_i, U_i$ where $T_i$ is the time to event and $U_i$ is time to censoring, i.e. end of follow up period. We can only observe the minimum of the two time, whichever comes the first, $T_i = min(Y_i,U_i)$. Hence the actual exact survival time (T) is usually unknown, mainly due to that the follow-up period is limited. Some instances are like when there is no event happened up to the end of the follow-up period, researchers lose contact with the patient, patient withdrawal participation, or the exact date of the event is unknown. So we would use censoring to account for the missing data issue. There are three types of censoring:

* Right censoring: $T \geq T_E$ Event happened after study period
* Left censoring: $T \leq T_0$ Event happened before study period
* Interval censoring: $T_A \leq T \leq T_B$ Only know event time interval but don't know the exact time

T: actual survival time   
$T_0$: Start of study period   
$T_E$: End of study period  

```{r ,echo=FALSE}
include_graphics("figures/f2_censor.jpg")
```
*Image credit to PHP2514 course material, Dr. Chrysanthopoulou*

For the Random Survival Forest method, we mainly focus on the right-censoring data.

## Hazard Function

Survival analysis involves three characteristic functions: survival function, hazard function, and cumulative hazard function, of which we can derive all three given any one of the functions. The random survival forest algorithm uses the cumulative hazard function. Hazard function and cumulative hazard function are written as:

Hazard function (hazard rate): instantaneous potential per unit time for the event to occur at time t, given survival up to time t:  

<img src="https://render.githubusercontent.com/render/math?math=h(t) = lim \Delta t \rightarrow 0 : \frac {P(t\leq T<t+\Delta t|T\geq t)} {\Delta(t)}">

<!-- $$h(t) = lim \Delta t \rightarrow 0 : \frac {P(t\leq T<t+\Delta t|T\geq t)} {\Delta(t)}$$ -->


```{r ,echo=FALSE}
include_graphics("figures/f3_weibull.jpg")
```
*Image credit to PHP2514 course material, Dr. Chrysanthopoulou*


Cumulative Hazard Function: integrate hazard function h(t) from time 0 to time t 

$$H(t)=\int_{0}^{t} h(u) \,du$$


# Regression Models for Survival Data

## Cox Porportional Hazards Model (semi-parametric)


* Y: [T, C]
  * T: Observed survival time
  * C: Censoring (or event) status

* Hazard rate:

Assume $h_0(t)$ as fixed and $X_j$ are **time-independent**: 
<img src="https://render.githubusercontent.com/render/math?math=h(t)=h_0(t)e^{\sum_{j=1}^p\beta_jX_j}">

$$h(t)=h_0(t)e^{\sum_{j=1}^p\beta_jX_j}$$
    



## PH assumption

Cox proportional hazards model is usually used for right censored  time-to-event data. Mode is convenient for flexibility and simplicity, but it's restricted to *proportional hazards (PH) assumptions*, which is to assume hazard ratio as independent of time t (constant over time). In other words, the hazard rate at any time point t for a set a covariate X* is **proportional** to the hazard rate at the same time point t for other set of covariate X.

Hazard Ratio $\theta$ is defined as:

<img src="https://render.githubusercontent.com/render/math?math=HR=\frac{h(t,X^*)}{h(t,X)}=e^{\sum_{j=1}^p\beta_j(X_j^*-X_j)}=\theta">

$$HR=\frac{h(t,X^*)}{h(t,X)}=e^{\sum_{j=1}^p\beta_j(X_j^*-X_j)}=\theta$$

Graphically, this is represented as roughly parallel survival curves between different categories of a covariate. For example, the graph below shows parallel pattern between high and low WBC, but non-parallel between medium and the others.


```{r ,echo=FALSE}
include_graphics("figures/f4.png")
```


## Survival Trees as alternative to Cox PH

When PH assumption is violated, which is most of the cases for real life data, we turn to survival trees and Random survival forest (RSF) models as alternative methods to the Cox PH model. (BMC Medical paper)

In contrast of the semi-parametric Cox PH model, survival trees is a fully *non-parametric* method, which is much more flexible and can easily handle high dimensional covariate data. And it can automatically detect certain types of **interactions** without the need to specify them beforehand. However, the drawback of survival trees is that it tends to be biased towards inclusion of variables with many split points. 

### Conditional Inference Forest (CIF)*:


"The random survival forests algorithm, has been criticised for having a bias towards selecting variables with many split points and the conditional inference forest algorithm has been identified as a method to reduce this selection bias. 
". As a further alternative to survival trees, CIF is able to correct bias in RSF "by separating the algorithm for selecting the best covariate to split on from that of the best split point search" (BMC paper)







-------------------------------

# Survival Random Forest / Survival Tree

Idea: partitioning the covariate space recursively to form groups of subjects who are similar according to the time-to-event outcome.
Minimizing a given impurity measure.
Goal: To identify prognostic factors that are predictive of the time-to-event outcome. 


## Split Rules:


### The log-rank split-rule ...

...
The best split at a node h, on a covariate x at a split point s âˆ— is the one that gives the largest log-rank statistic between the two daughter nodes
..


### The log-rank score split-rule ...

...
Trees are generally unstable and hence researchers have recommended the growing of a collection of trees [10, 27], commonly referred to as random survival forests [20, 26].



# Application in R


# Veteran Data

In this demo we're using ``veteran`` data from ``survival`` package, which records data of randomized trial of two treatment regimens for lung cancer. For model fitting, we need ``survival`` library for cox ph model and ``ranger`` library for random survival forest. 

```{r,echo=FALSE}
read.csv('figures/veteran.csv')  %>% kable(caption = 'Veteran Data')
library(data.table)
```

First, we split data into training set and test set:

```{r,message=FALSE,warning=FALSE}
library(survival)
library(ranger)
data(veteran)
veteran <- data.table(veteran)
vet = veteran

# Next, we split the data in a training and test set.
set.seed(123456)
ind <- sample(1:nrow(veteran),round(nrow(veteran) * 0.7,0))
veteran_train <- veteran[ind,]
veteran_test <- veteran[!ind,]
vet.tr = vet[ind,]
vet.te = vet[-ind,]
```


Use Kaplan Meier Curve as a visual summary of the survival probability between treatment groups:

```{r}
# plot survival curve:
kmvet = survfit(Surv(time, status)~trt, data=vet)
# km curve
plot(kmvet, col=c('blue','red'), xlab='Time', ylab='Survival Probability', main='Kaplan Meier Curves')
legend("topright", lwd = 1, col = c('blue','red'), cex=0.7, y.intersp = 0.5, legend = c('trt=1', 'trt=2'))
abline(h=0.5,lty=3)
```


## Cox PH Model

We first fit a COX PH Model. Using backward selection, we found the 'best' variable to fit the data. However, the log-log survival curves show non-parallel curves between variable groups. So the PH assumption might be violated. 

```{r, results=FALSE}
coxm0 = coxph(Surv(time, status)~(celltype+trt+karno+diagtime+age+prior)^2, data=vet.tr, ties='breslow')
# coxm1 = step(coxm0, direction = "backward")

# model selected from backward selection
coxm1 = coxph(formula = Surv(time, status) ~ celltype + trt + karno + diagtime + prior + 
    celltype:trt + trt:karno + trt:diagtime + trt:prior + karno:prior, data = vet.tr, ties = "breslow")
# summary(coxm1)

# PH assumption: non-parallel, violated
par(mfrow=c(2,2))
sapply(list(vet.tr$trt, vet.tr$celltype, vet.tr$karno, vet.tr$prior), 
       function(var) plot(survfit(Surv(time, status) ~ var, data=vet.tr),
                          col=1:10,
                          fun="cloglog",
                          ylab='log(-log(S(t)))', 
                          xlab='log(time)',
                          xlim=c(20,250),
                          ylim=c(-2,0.5),
                          main='Log-Log Survival Curves')
)
```

The goodness of fit test based on Schoenfeld Residuals is another way to test the PH assumption, which is the null hypothesis. However, we can see a lot of p values of less than 0.05, this validated our concern that the proportional hazard assumption is violated.

```{r}
cox.zph(coxm1) 
```


## Random Survival Models

### Use ranger package to train the random survival models

Recall that in random forest, we need to find number of variables **mtry ** to randomly select from at each node.  First, we find the optimal mtry parameter that gives the smallest OOB error. Over 1000 iterations, m = 3 has the highest frequency of giving the smallest OOB error. 

```{r}
par(mfrow=c(1,1))
# I created a simple function to find best m:
functune = function(m){
  sapply(1:6, function(m) ranger(Surv(time, status) ~ .,
                data = veteran_train,
                mtry = m,
                verbose = TRUE,
                write.forest=TRUE,
                num.trees= 1000,
                importance = 'permutation')$prediction.error)
}
# I commented out this line of code to save running time: 
# findM = apply(replicate(100,functune()), 2, which.min)
# save(findM, file='findM')
load(file='findM')
# m = 3 is the optimal m
table(findM)
```



So we fit random survival tree with m = 3. 

```{r}
# fit random survival tree
r_fit <- ranger(Surv(time, status) ~ .,
                data = veteran_train,
                mtry = 3,
                verbose = TRUE,
                write.forest=TRUE,
                num.trees= 1000,
                importance = 'permutation')
```

### Fitted Survival probability

The model gives the fitted survival probability in a table format, where rows represent individual patient and columns represent event time points, from beginning to the end. Below I'm showing a snapshot of the fitted survival probability table.

```{r}
# distinct survival time in training data
# r_fit$unique.death.times

# fitted survival: survival probability
# rows represent individual patient; columns represent event time points
fit.surv = r_fit$survival
fit.survdf = data.frame(fit.surv)
colnames(fit.survdf) <- paste0('T',as.character(r_fit$unique.death.times))
# write.csv(fit.survdf, file = 'fit.survdf.csv')
# fit.survdf = read.csv('fit.survdf.csv')
fit.survdf[1:5,1:6]

```

Then I sampled 4 individuals to plot fitted survival curve.

```{r}
par(mfrow=c(1,1))
set.seed(12345)
individual = sample(1:dim(veteran_train)[1], 4)
plot(r_fit$unique.death.times, fit.surv[individual[1],], type = 'l', col = 'red',xlab='Time', ylab='Survival Probability', main='Fitted Survival Curve (4 individuals)')
lines(r_fit$unique.death.times,fit.surv[individual[2],], type = 'l', col = 'blue',xlab='Time', ylab='Survival Probability')
lines(r_fit$unique.death.times,fit.surv[individual[3],], type = 'l', col = 'green',xlab='Time', ylab='Survival Probability')
lines(r_fit$unique.death.times,fit.surv[individual[4],], type = 'l', col = 'pink',xlab='Time', ylab='Survival Probability')
abline(v=veteran_train[individual,]$time, lty=3, col=c('red','blue','green','pink'))
legend("topright", lwd = 1, col = c('red','blue','green','pink'),
       legend = c('id14', 'id51', 'id80', 'id90'))

veteran_train[individual,]
```

### Variable Importance

The random survival forest model identified karno, celltype, and trt as the three most important predictors of survival time.

```{r}
# r_fit$variable.importance
# plot(r_fit$variable.importance)
data.frame(r_fit$variable.importance) %>% arrange(desc(r_fit.variable.importance))
```


Similarly, in Cox PH model, the interaction effects between treatment and celltype, karno, diagtime, prior are significant, hence can be considered as important in affecting survival probability. 

```{r}
coxm1
```


### Model performance 

To assess the model performance, I choose to predict proportional of survival after 80 days: if survival probability of an individual is over 50% at time T, then he is predicted to be survived. The preidction accuracy at time point 80 is 63%.


```{r}
preds <- predict(r_fit, veteran_test, type = 'response')$survival
preds = data.frame(preds)
colnames(preds) <- paste0('T',as.character(r_fit$unique.death.times))

predEvent = preds$T80 > 0.5
actualEvent = veteran_test$time >= 80
accuracy = sum(predEvent==actualEvent)/length(actualEvent)

table(predEvent, actualEvent)
accuracy

```


To generalize the performance result, I predicted survival rates for all time points. Prediction accuracy is as below:
Note that the x-axis represents the time index, not the actual time point period.

```{r}
# predict more time point:
# exrtact time integer from column names:
times = as.numeric(substr(colnames(preds),start=2,5))
  
predSurv = function(j){
  # predict survival status:
  predEvent = preds[,j] > 0.5
  actualEvent = veteran_test$time >= times[j]
  # return confusion matrix and accuracy
  return(list(table(predEvent, actualEvent),
              sum(predEvent==actualEvent)/length(actualEvent)))
}
# apply the prediction to all time points:
accuracy_list = sapply(1:dim(preds)[2], function(j) predSurv(j)[[2]])
# plot accuracy
plot(accuracy_list,type='o',pch=16, main='Prediction accuracy by time', xlab='Time Index', ylab='Accuracy')
```



